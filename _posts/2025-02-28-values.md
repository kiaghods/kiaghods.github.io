---
layout: post
title: On the Question of Values
date: 2025-02-28
description: This post abstractly discusses how advancing AI challenges societal values, prompting a redefinition of intelligence and mastery while urging deeper reflection on human purpose in a technologically transformed world.
categories: reflections
---

*This is my first attempt at blog-style short-form writing.*

### Introduction

As technology evolves, society quietly updates what it values. Memory externalization—offloading recall to tools—isn't new. Rolodexes alphabetized our professional lives in the 1950s, freeing us from memorizing countless contacts. GPS does much the same today, gradually chipping away at our innate navigation skills.

Now, Artificial Intelligence (AI) enters the scene, and in particular Large Language Models (LLMs). These tools don’t just assist with recall; they answer complex questions, solve intricate problems, and generate novel ideas.

### AI: Beyond Specific Cognitive Tasks

Earlier tools typically handled one cognitive job at a time. AI, however, is a generalist. This pivotal difference forces us to ask: **What happens to the societal value of intelligence—long prized—when it becomes abundant and easily outsourceable?**

Chess offers a compelling clue. Computers now dominate the world’s best human players. Yet, people continue to play – for the joy of the game, the pursuit of personal progress, the beauty of strategy. It's clearly not just about being the absolute best; it’s about the journey and the engagement.

From this example, we see that chess players continue their craft, even when "outperformed" by automated systems or other experts. In this light, mastery begins to look less like ultimate supremacy and more like a meaningful, evolving interaction with systems—and people—that push our boundaries.

And no, this doesn't mean we'll simply flee to supposedly "human-only" traits like creativity as our primary value. People will likely still strive for technical mastery—just as they do in chess—not despite AI, but often *because of* the new challenges and possibilities it presents.

### Redefining Mastery and Value in an AI-Abundant World

Expertise, and what we value in it, might soon be defined more by knowing *how to effectively use* AI than by possessing standalone knowledge. Enter: prompting, tool use, etc.

This shift mirrors historical precedents. When calculators became commonplace, the emphasis in math education shifted from rote arithmetic to understanding concepts. When Google arrived, sheer recall mattered less than knowing how to formulate good questions and critically evaluate the results. This re-evaluation of skills inherently changes what we value.

Tomorrow’s “smart” individual might be the one who discerns when *not* to ask ChatGPT[^1], who can deftly orchestrate a suite of AI tools rather than merely operate a single one. This discernment itself becomes a valued skill.

AI literacy is rapidly becoming foundational. Understanding what AI can (and crucially, *cannot*) do reliably may soon be as essential as reading and writing were in previous eras. Just as those skills transitioned from specialist domains to universal necessities, so too might AI savvy.

### The Psychological Adaptation: Human Value in the Age of AI

What does it mean to be human, and what do we value in ourselves, when the language model seems "smarter" than you?

Humans have often defined their uniqueness by abilities they believed were exclusively theirs: complex language, abstract reason, sophisticated tool-building. Each time technology has blurred these boundaries, we've been forced to rethink our identity and, consequently, what we value about being human.

Now, AI is externalizing cognition itself, moving it beyond the confines of the human skull. Some will enthusiastically embrace this, viewing AI as a cognitive partner. Others might seek refuge in aspects of humanity they perceive as less replicable: empathy, embodiment, deep interpersonal connection. And many may begin to realize that intelligence, perhaps, was never a purely solo endeavor—it was always, to some degree, relational and contextual.

In that light, the potential discomfort of being "less smart" than a machine isn't a demotion, but an opportunity to fundamentally rethink what intelligence truly is, and how (and why) we value it.

### Conclusion: AI as a Mirror for Our Values

We’re not just outsourcing memory or computation anymore. We're beginning to outsource aspects of *thinking* itself. But this doesn’t inherently diminish us; in some ways, it can liberate us to redefine what's truly valuable.

Freed, perhaps, from the relentless race to simply “know more” or "compute faster," we can delve deeper into what it means to live well. To ask more profound questions. To connect more deeply with each other. To play, explore, and create with new purpose.

AI isn't just another tool. It's rapidly becoming a mirror. And as we gaze into it, we're not just seeing the future of technology; we're being prompted to rediscover and reaffirm the values that were most important all along.

[^1]: Note that _ChatGPT_ serves as a common example here. 